{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom mpl_toolkits.axes_grid1 import ImageGrid # for plotting the images as graphs\n\nimport cv2 # masking images\nfrom glob import glob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Input\nfrom keras.layers import InputLayer, MaxPooling2D, Flatten, Dense, Conv2D, Dropout\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing import image \nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50  #VGG-16\nfrom tensorflow.keras.optimizers import Adam, SGD # (adagrad + momentum)  SGD-->(stochastic gradient descent)\nfrom tensorflow.keras import backend as K #cache \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom PIL.Image import open\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nfrom tensorflow.keras.models import Model, load_model, save_model  # controls modelling\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\n\nimport seaborn as sns\nfrom  matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nimport random\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:03.669829Z","iopub.execute_input":"2022-09-07T09:51:03.670768Z","iopub.status.idle":"2022-09-07T09:51:10.982542Z","shell.execute_reply.started":"2022-09-07T09:51:03.670666Z","shell.execute_reply":"2022-09-07T09:51:10.981537Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Constants\nIMAGE_DATASET = \"../input/brain-tumor/Brain Tumor/Brain Tumor\"\nIMAGE_DATASET_RAW = r\"..\\input\\brain-tumor\\Brain Tumor\\Brain Tumor\"\nWORKING_FOLDER = \"/kaggle/working\"\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:10.984605Z","iopub.execute_input":"2022-09-07T09:51:10.985297Z","iopub.status.idle":"2022-09-07T09:51:10.992391Z","shell.execute_reply.started":"2022-09-07T09:51:10.985260Z","shell.execute_reply":"2022-09-07T09:51:10.990919Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# We will import the csv file containing the features and the classes of the images\ncortex_df = pd.read_csv(\"../input/brain-tumor/Brain Tumor.csv\")\ncortex_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:10.997130Z","iopub.execute_input":"2022-09-07T09:51:10.997562Z","iopub.status.idle":"2022-09-07T09:51:11.072328Z","shell.execute_reply.started":"2022-09-07T09:51:10.997526Z","shell.execute_reply":"2022-09-07T09:51:11.071310Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cortex_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:11.075061Z","iopub.execute_input":"2022-09-07T09:51:11.075750Z","iopub.status.idle":"2022-09-07T09:51:11.082110Z","shell.execute_reply.started":"2022-09-07T09:51:11.075711Z","shell.execute_reply":"2022-09-07T09:51:11.080996Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = cortex_df.corr()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:11.083488Z","iopub.execute_input":"2022-09-07T09:51:11.084409Z","iopub.status.idle":"2022-09-07T09:51:11.114976Z","shell.execute_reply.started":"2022-09-07T09:51:11.084374Z","shell.execute_reply":"2022-09-07T09:51:11.113862Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(df,annot=True)\nplt.title('Correlation between the paramters')  # Spearman's Matrix","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:11.116169Z","iopub.execute_input":"2022-09-07T09:51:11.116578Z","iopub.status.idle":"2022-09-07T09:51:12.006646Z","shell.execute_reply.started":"2022-09-07T09:51:11.116541Z","shell.execute_reply":"2022-09-07T09:51:12.005774Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nIMAGE_SIZE = (256, 256) ","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:12.007997Z","iopub.execute_input":"2022-09-07T09:51:12.008296Z","iopub.status.idle":"2022-09-07T09:51:12.013119Z","shell.execute_reply.started":"2022-09-07T09:51:12.008269Z","shell.execute_reply":"2022-09-07T09:51:12.011912Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mask_files = glob('../input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\ntrain_files = [file.replace('_mask', '') for file in mask_files]","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:12.014740Z","iopub.execute_input":"2022-09-07T09:51:12.015371Z","iopub.status.idle":"2022-09-07T09:51:15.006125Z","shell.execute_reply.started":"2022-09-07T09:51:12.015335Z","shell.execute_reply":"2022-09-07T09:51:15.005149Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                   \"mask_path\": mask_files,\n                  \"diagnosis\":[diagnosis(x) for x in mask_files]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:15.009579Z","iopub.execute_input":"2022-09-07T09:51:15.009895Z","iopub.status.idle":"2022-09-07T09:51:52.257017Z","shell.execute_reply.started":"2022-09-07T09:51:15.009849Z","shell.execute_reply":"2022-09-07T09:51:52.255911Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\ntest_folder=\"../input/brain-tumor/Brain Tumor/Brain Tumor\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:52.262144Z","iopub.execute_input":"2022-09-07T09:51:52.262430Z","iopub.status.idle":"2022-09-07T09:51:52.921256Z","shell.execute_reply.started":"2022-09-07T09:51:52.262404Z","shell.execute_reply":"2022-09-07T09:51:52.917928Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset_df = pd.DataFrame()\ndataset_df[\"Image\"] = cortex_df[\"Image\"]\ndataset_df[\"Class\"] = cortex_df[\"Class\"]\npath_list = []\nfor img_path in os.listdir(IMAGE_DATASET):\n    path_list.append( os.path.join(IMAGE_DATASET,img_path))\npath_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in path_list}\ndataset_df[\"paths\"] = cortex_df[\"Image\"].map(path_dict.get)\ndataset_df[\"pixels\"] = dataset_df[\"paths\"].map(lambda x:np.asarray(open(x).resize((IMG_HEIGHT,IMG_WIDTH))))\ndataset_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:51:52.923670Z","iopub.execute_input":"2022-09-07T09:51:52.924340Z","iopub.status.idle":"2022-09-07T09:52:42.811881Z","shell.execute_reply.started":"2022-09-07T09:51:52.924295Z","shell.execute_reply":"2022-09-07T09:52:42.810753Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ax = df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(10,6), color=['blue', 'red'])\nax.set_title('Data Distribution')\nax.set_ylabel('Total Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:42.813514Z","iopub.execute_input":"2022-09-07T09:52:42.813906Z","iopub.status.idle":"2022-09-07T09:52:43.018859Z","shell.execute_reply.started":"2022-09-07T09:52:42.813856Z","shell.execute_reply":"2022-09-07T09:52:43.017908Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_positive = df[df['diagnosis']=='1'].sample(5).values  # cases where tumor is found\ndf_negative = df[df['diagnosis']=='0'].sample(5).values  # cases where tumor is not found\n\ndef show_data(df, positive=True):\n    images = []\n    masks = []\n    for data in df:\n        img = cv2.imread(data[0])\n        mask = cv2.imread(data[1])\n        images.append(img)\n        masks.append(mask)\n    images = np.hstack(np.array(images))\n    masks = np.hstack(np.array(masks))\n    \n    fig = plt.figure(figsize=(25,25))\n    if positive:\n        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n    else:\n        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n    grid[0].imshow(images)\n    grid[0].set_title('Images', fontsize=15)\n    grid[0].axis('off')\n    grid[1].imshow(masks)\n    grid[1].set_title('Masks', fontsize=15)\n    grid[1].axis('off')\n    if positive:\n        grid[2].imshow(images)\n        grid[2].imshow(masks, alpha=0.4)\n        grid[2].set_title('Brain MRI with mask', fontsize=15)\n        grid[2].axis('off')\n        \nshow_data(df_positive)\nshow_data(df_negative, positive=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:43.020410Z","iopub.execute_input":"2022-09-07T09:52:43.020748Z","iopub.status.idle":"2022-09-07T09:52:45.598624Z","shell.execute_reply.started":"2022-09-07T09:52:43.020713Z","shell.execute_reply":"2022-09-07T09:52:45.597803Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"image_list = []\nfor i in range(len(dataset_df)):\n    brain_image = dataset_df[\"pixels\"][i].astype(np.float32)\n    brain_image /= 255\n    image_list.append(brain_image)\nX = np.array(image_list)\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:45.600572Z","iopub.execute_input":"2022-09-07T09:52:45.601196Z","iopub.status.idle":"2022-09-07T09:52:47.933186Z","shell.execute_reply.started":"2022-09-07T09:52:45.601161Z","shell.execute_reply":"2022-09-07T09:52:47.932116Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y = np.array(dataset_df.Class)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:47.934626Z","iopub.execute_input":"2022-09-07T09:52:47.935136Z","iopub.status.idle":"2022-09-07T09:52:47.943177Z","shell.execute_reply.started":"2022-09-07T09:52:47.935098Z","shell.execute_reply":"2022-09-07T09:52:47.941997Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:47.944896Z","iopub.execute_input":"2022-09-07T09:52:47.945471Z","iopub.status.idle":"2022-09-07T09:52:47.956766Z","shell.execute_reply.started":"2022-09-07T09:52:47.945423Z","shell.execute_reply":"2022-09-07T09:52:47.955472Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nprint('The shape of the X_train :'+' '+str(X_train.shape))\nprint('The size of the X_train :'+' '+str(X_train.shape[0]))\nprint('The shape of the X_test :'+' '+str(X_test.shape))\nprint('The size of the X_test:'+' '+str(X_test.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:47.958160Z","iopub.execute_input":"2022-09-07T09:52:47.959155Z","iopub.status.idle":"2022-09-07T09:52:48.605358Z","shell.execute_reply.started":"2022-09-07T09:52:47.959118Z","shell.execute_reply":"2022-09-07T09:52:48.604352Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def model(input_shape):\n#     res_conv = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=input_shape, pooling=None)\n    model = Sequential()\n    \n    model.add(Input(shape=input_shape))\n\n    model.add(Conv2D(16, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(16, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n            \n    model.add(Conv2D(32, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(32, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n    \n    model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n    \n     \n    model.add(Flatten())\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dense(128, activation=\"relu\"))\n#     model.add(Dropout(0.4))\n    model.add(Dense(1, activation=\"sigmoid\"))    # Never use sigmoid for binary classification\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:48.607513Z","iopub.execute_input":"2022-09-07T09:52:48.608581Z","iopub.status.idle":"2022-09-07T09:52:48.619420Z","shell.execute_reply.started":"2022-09-07T09:52:48.608540Z","shell.execute_reply":"2022-09-07T09:52:48.618418Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = model(input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:48.620810Z","iopub.execute_input":"2022-09-07T09:52:48.621922Z","iopub.status.idle":"2022-09-07T09:52:51.574665Z","shell.execute_reply.started":"2022-09-07T09:52:48.621886Z","shell.execute_reply":"2022-09-07T09:52:51.573541Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\",)\noptimizer = SGD(learning_rate=0.01)\nloss_fn = BinaryCrossentropy(from_logits=True)\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])  # f1 score","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:51.576016Z","iopub.execute_input":"2022-09-07T09:52:51.576932Z","iopub.status.idle":"2022-09-07T09:52:51.591314Z","shell.execute_reply.started":"2022-09-07T09:52:51.576887Z","shell.execute_reply":"2022-09-07T09:52:51.590216Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Training the model\nhistory = model.fit(x=X_train, y=y_train, epochs=EPOCHS, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:52:51.593275Z","iopub.execute_input":"2022-09-07T09:52:51.593824Z","iopub.status.idle":"2022-09-07T09:55:17.799303Z","shell.execute_reply.started":"2022-09-07T09:52:51.593789Z","shell.execute_reply":"2022-09-07T09:55:17.798215Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"eval_score = model.evaluate(X_test, y_test)\nprint(\"Test loss:\", eval_score[0])\nprint(\"Test accuracy:\", eval_score[1])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:17.800900Z","iopub.execute_input":"2022-09-07T09:55:17.801366Z","iopub.status.idle":"2022-09-07T09:55:19.275990Z","shell.execute_reply.started":"2022-09-07T09:55:17.801329Z","shell.execute_reply":"2022-09-07T09:55:19.275033Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(\"The maximum accuracy obtained = {0:.2f}\".format(eval_score[1]*100),\"%\")","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.277275Z","iopub.execute_input":"2022-09-07T09:55:19.278298Z","iopub.status.idle":"2022-09-07T09:55:19.284087Z","shell.execute_reply.started":"2022-09-07T09:55:19.278258Z","shell.execute_reply":"2022-09-07T09:55:19.282930Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255.\n    mask = mask / 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.285267Z","iopub.execute_input":"2022-09-07T09:55:19.286118Z","iopub.status.idle":"2022-09-07T09:55:19.326911Z","shell.execute_reply.started":"2022-09-07T09:55:19.286082Z","shell.execute_reply":"2022-09-07T09:55:19.325902Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.328762Z","iopub.execute_input":"2022-09-07T09:55:19.329226Z","iopub.status.idle":"2022-09-07T09:55:19.349658Z","shell.execute_reply.started":"2022-09-07T09:55:19.329192Z","shell.execute_reply":"2022-09-07T09:55:19.348735Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nEPOCHS = 4\nBATCH_SIZE = 2\nlearning_rate = 1e-2","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.351045Z","iopub.execute_input":"2022-09-07T09:55:19.351454Z","iopub.status.idle":"2022-09-07T09:55:19.363330Z","shell.execute_reply.started":"2022-09-07T09:55:19.351417Z","shell.execute_reply":"2022-09-07T09:55:19.362342Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"smooth = 1,\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) / (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.364662Z","iopub.execute_input":"2022-09-07T09:55:19.365189Z","iopub.status.idle":"2022-09-07T09:55:19.375217Z","shell.execute_reply.started":"2022-09-07T09:55:19.365154Z","shell.execute_reply":"2022-09-07T09:55:19.374374Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \nval_gen = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    \nmodel = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n\n\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\nmodel.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brainMRI_seg.hdf5', verbose=0, save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=15)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = val_gen,\n                    validation_steps=len(df_val) / BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T09:55:19.383701Z","iopub.execute_input":"2022-09-07T09:55:19.383978Z","iopub.status.idle":"2022-09-07T10:03:47.601756Z","shell.execute_reply.started":"2022-09-07T09:55:19.383954Z","shell.execute_reply":"2022-09-07T10:03:47.600684Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:03:47.605332Z","iopub.execute_input":"2022-09-07T10:03:47.606802Z","iopub.status.idle":"2022-09-07T10:03:58.046035Z","shell.execute_reply.started":"2022-09-07T10:03:47.606758Z","shell.execute_reply":"2022-09-07T10:03:58.045126Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:03:58.047575Z","iopub.execute_input":"2022-09-07T10:03:58.048539Z","iopub.status.idle":"2022-09-07T10:04:12.855991Z","shell.execute_reply.started":"2022-09-07T10:03:58.048501Z","shell.execute_reply":"2022-09-07T10:04:12.854810Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"loss = history.history[\"loss\"]  # loss function (MSE)\nacc = history.history[\"accuracy\"] ","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:28.546456Z","iopub.execute_input":"2022-09-07T10:05:28.546831Z","iopub.status.idle":"2022-09-07T10:05:28.570856Z","shell.execute_reply.started":"2022-09-07T10:05:28.546799Z","shell.execute_reply":"2022-09-07T10:05:28.569759Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy by UNet: \",results[2]*100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:34.956548Z","iopub.execute_input":"2022-09-07T10:05:34.956926Z","iopub.status.idle":"2022-09-07T10:05:34.962662Z","shell.execute_reply.started":"2022-09-07T10:05:34.956889Z","shell.execute_reply":"2022-09-07T10:05:34.961615Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, loss)\n# plt.plot(epoch, val_loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend(['train', 'val'])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:36.060171Z","iopub.execute_input":"2022-09-07T10:05:36.062167Z","iopub.status.idle":"2022-09-07T10:05:36.275777Z","shell.execute_reply.started":"2022-09-07T10:05:36.062121Z","shell.execute_reply":"2022-09-07T10:05:36.274798Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, acc)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:37.535741Z","iopub.execute_input":"2022-09-07T10:05:37.536415Z","iopub.status.idle":"2022-09-07T10:05:37.561459Z","shell.execute_reply.started":"2022-09-07T10:05:37.536379Z","shell.execute_reply":"2022-09-07T10:05:37.560073Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/mri-and-alzheimers/oasis_longitudinal.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:38.746834Z","iopub.execute_input":"2022-09-07T10:05:38.747443Z","iopub.status.idle":"2022-09-07T10:05:38.777195Z","shell.execute_reply.started":"2022-09-07T10:05:38.747402Z","shell.execute_reply":"2022-09-07T10:05:38.776158Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\ndf = df.reset_index(drop=True) # reset index after filtering first visit data\ndf['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\ndf['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\ndf['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\ndf = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:39.724444Z","iopub.execute_input":"2022-09-07T10:05:39.724799Z","iopub.status.idle":"2022-09-07T10:05:39.751776Z","shell.execute_reply.started":"2022-09-07T10:05:39.724767Z","shell.execute_reply":"2022-09-07T10:05:39.750881Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# bar drawing function\ndef bar_chart(feature):\n    Demented = df[df['Group']==1][feature].value_counts()\n    Nondemented = df[df['Group']==0][feature].value_counts()\n    df_bar = pd.DataFrame([Demented,Nondemented])\n    df_bar.index = ['Demented','Nondemented']\n    df_bar.plot(kind='bar',stacked=True, figsize=(8,5))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:40.920155Z","iopub.execute_input":"2022-09-07T10:05:40.920511Z","iopub.status.idle":"2022-09-07T10:05:40.927060Z","shell.execute_reply.started":"2022-09-07T10:05:40.920479Z","shell.execute_reply":"2022-09-07T10:05:40.926067Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**MALE FEMALE**","metadata":{}},{"cell_type":"code","source":"# Gender  and  Group ( Femal=0, Male=1)\nbar_chart('M/F')\nplt.xlabel('Group')\nplt.ylabel('Number of patients')\nplt.legend()\nplt.title('Gender and Demented rate')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:43.200148Z","iopub.execute_input":"2022-09-07T10:05:43.200749Z","iopub.status.idle":"2022-09-07T10:05:43.426770Z","shell.execute_reply.started":"2022-09-07T10:05:43.200712Z","shell.execute_reply":"2022-09-07T10:05:43.425821Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"**DISTRIBUTION DENSITY**","metadata":{}},{"cell_type":"code","source":"facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'MMSE',shade= True)\nfacet.set(xlim=(0, df['MMSE'].max()))\nfacet.add_legend()\nplt.xlim(15.30)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:45.748171Z","iopub.execute_input":"2022-09-07T10:05:45.749000Z","iopub.status.idle":"2022-09-07T10:05:46.132677Z","shell.execute_reply.started":"2022-09-07T10:05:45.748958Z","shell.execute_reply":"2022-09-07T10:05:46.131736Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#bar_chart('ASF') = Atlas Scaling Factor\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'ASF',shade= True)\nfacet.set(xlim=(0, df['ASF'].max()))\nfacet.add_legend()\nplt.xlim(0.5, 2)\n\n#eTIV = Estimated Total Intracranial Volume\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'eTIV',shade= True)\nfacet.set(xlim=(0, df['eTIV'].max()))\nfacet.add_legend()\nplt.xlim(900, 2100)\n\n#'nWBV' = Normalized Whole Brain Volume\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'nWBV',shade= True)\nfacet.set(xlim=(0, df['nWBV'].max()))\nfacet.add_legend()\nplt.xlim(0.6,0.9)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:47.597082Z","iopub.execute_input":"2022-09-07T10:05:47.598065Z","iopub.status.idle":"2022-09-07T10:05:48.604888Z","shell.execute_reply.started":"2022-09-07T10:05:47.598018Z","shell.execute_reply":"2022-09-07T10:05:48.603758Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#AGE. Nondemented =0, Demented =0\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(50,100)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:49.660807Z","iopub.execute_input":"2022-09-07T10:05:49.662216Z","iopub.status.idle":"2022-09-07T10:05:50.105803Z","shell.execute_reply.started":"2022-09-07T10:05:49.662166Z","shell.execute_reply":"2022-09-07T10:05:50.104760Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#'EDUC' = Years of Education\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'EDUC',shade= True)\nfacet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\nfacet.add_legend()\nplt.ylim(0, 0.16)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:51.320634Z","iopub.execute_input":"2022-09-07T10:05:51.321043Z","iopub.status.idle":"2022-09-07T10:05:51.678637Z","shell.execute_reply.started":"2022-09-07T10:05:51.321009Z","shell.execute_reply":"2022-09-07T10:05:51.677598Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Draw scatter plot between EDUC and SES\nx = df['EDUC']\ny = df['SES']\n\nses_not_null_index = y[~y.isnull()].index\nx = x[ses_not_null_index]\ny = y[ses_not_null_index]\n\n# Draw trend line in red\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x, y, 'go', x, p(x), \"r--\")\nplt.xlabel('Education Level(EDUC)')\nplt.ylabel('Social Economic Status(SES)')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:52.888444Z","iopub.execute_input":"2022-09-07T10:05:52.888807Z","iopub.status.idle":"2022-09-07T10:05:53.095989Z","shell.execute_reply.started":"2022-09-07T10:05:52.888775Z","shell.execute_reply":"2022-09-07T10:05:53.094933Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df.groupby(['EDUC'])['SES'].median()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:54.362719Z","iopub.execute_input":"2022-09-07T10:05:54.363383Z","iopub.status.idle":"2022-09-07T10:05:54.379063Z","shell.execute_reply.started":"2022-09-07T10:05:54.363349Z","shell.execute_reply":"2022-09-07T10:05:54.377907Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)\n# I confirm there're no more missing values and all the 150 data were used.\npd.isnull(df['SES']).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:55.602376Z","iopub.execute_input":"2022-09-07T10:05:55.603537Z","iopub.status.idle":"2022-09-07T10:05:55.614187Z","shell.execute_reply.started":"2022-09-07T10:05:55.603491Z","shell.execute_reply":"2022-09-07T10:05:55.613064Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler \nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:57.058267Z","iopub.execute_input":"2022-09-07T10:05:57.058963Z","iopub.status.idle":"2022-09-07T10:05:57.064109Z","shell.execute_reply.started":"2022-09-07T10:05:57.058909Z","shell.execute_reply":"2022-09-07T10:05:57.062708Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Dataset with imputation\nY = df['Group'].values # Target for the model\nX = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n\n# splitting into three sets\nX_trainval, X_test, Y_trainval, Y_test = train_test_split(\n    X, Y, random_state=0)\n\n# Feature scaling\nscaler = MinMaxScaler().fit(X_trainval)\nX_trainval_scaled = scaler.transform(X_trainval)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:05:58.479374Z","iopub.execute_input":"2022-09-07T10:05:58.481978Z","iopub.status.idle":"2022-09-07T10:05:58.504482Z","shell.execute_reply.started":"2022-09-07T10:05:58.481930Z","shell.execute_reply":"2022-09-07T10:05:58.503567Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"**DETECTION OF ALZHEIMER'S DUE TO PRESENCE OF TUMOUR**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc\nacc = [] # list to store all performance metric","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:01.124656Z","iopub.execute_input":"2022-09-07T10:06:01.125192Z","iopub.status.idle":"2022-09-07T10:06:01.386661Z","shell.execute_reply.started":"2022-09-07T10:06:01.125159Z","shell.execute_reply":"2022-09-07T10:06:01.385535Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"best_score=0\nkfolds=5 # set the number of folds\n\nfor c in [0.001, 0.1, 1, 10, 100]:\n    logRegModel = LogisticRegression(C=c)\n    # perform cross-validation\n    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n    \n    # compute mean cross-validation accuracy\n    score = np.mean(scores)\n    \n    # Find the best parameters and score\n    if score > best_score:\n        best_score = score\n        best_parameters = c\n\n# rebuild a model on the combined training and validation set\nSelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled, Y_trainval)\n\ntest_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter for regularization (C) is: \", best_parameters)\nprint(\"Test accuracy (F1 Score) with best C parameter is\", test_score)\nprint(\"Test recall with the best C parameter is\", test_recall)\nprint(\"Test AUC with the best C parameter is\", test_auc)\nm = 'Logistic Regression (w/ imputation)'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:03.411345Z","iopub.execute_input":"2022-09-07T10:06:03.411707Z","iopub.status.idle":"2022-09-07T10:06:03.931632Z","shell.execute_reply.started":"2022-09-07T10:06:03.411676Z","shell.execute_reply":"2022-09-07T10:06:03.930621Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"**SVM**","metadata":{}},{"cell_type":"code","source":"best_score = 0\n\nfor c_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter C\n    for gamma_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter gamma\n        for k_parameter in ['rbf', 'linear', 'poly', 'sigmoid']: # iterate over the values we need to try for the kernel parameter\n            svmModel = SVC(kernel=k_parameter, C=c_paramter, gamma=gamma_paramter) #define the model\n            # perform cross-validation\n            scores = cross_val_score(svmModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n            # the training set will be split internally into training and cross validation\n\n            # compute mean cross-validation accuracy\n            score = np.mean(scores)\n            # if we got a better score, store the score and parameters\n            if score > best_score:\n                best_score = score #store the score \n                best_parameter_c = c_paramter #store the parameter c\n                best_parameter_gamma = gamma_paramter #store the parameter gamma\n                best_parameter_k = k_parameter\n            \n\n# rebuild a model with best parameters to get score \nSelectedSVMmodel = SVC(C=best_parameter_c, gamma=best_parameter_gamma, kernel=best_parameter_k).fit(X_trainval_scaled, Y_trainval)\n\ntest_score = SelectedSVMmodel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedSVMmodel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on cross validation set is:\", best_score)\nprint(\"Best parameter for c is: \", best_parameter_c)\nprint(\"Best parameter for gamma is: \", best_parameter_gamma)\nprint(\"Best parameter for kernel is: \", best_parameter_k)\nprint(\"Test accuracy with the best parameters is\", test_score)\nprint(\"Test recall with the best parameters is\", test_recall)\nprint(\"Test recall with the best parameter is\", test_auc)\n\nm = 'SVM'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:05.557637Z","iopub.execute_input":"2022-09-07T10:06:05.558312Z","iopub.status.idle":"2022-09-07T10:06:11.237193Z","shell.execute_reply.started":"2022-09-07T10:06:05.558279Z","shell.execute_reply":"2022-09-07T10:06:11.236052Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree**","metadata":{}},{"cell_type":"code","source":"best_score = 0\n\nfor md in range(1, 9): # iterate different maximum depth values\n    # train the model\n    treeModel = DecisionTreeClassifier(random_state=0, max_depth=md, criterion='gini')\n    # perform cross-validation\n    scores = cross_val_score(treeModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n    \n    # compute mean cross-validation accuracy\n    score = np.mean(scores)\n    \n    # if we got a better score, store the score and parameters\n    if score > best_score:\n        best_score = score\n        best_parameter = md\n\n# Rebuild a model on the combined training and validation set        \nSelectedDTModel = DecisionTreeClassifier(max_depth=best_parameter).fit(X_trainval_scaled, Y_trainval )\n\ntest_score = SelectedDTModel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedDTModel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter for the maximum depth is: \", best_parameter)\nprint(\"Test accuracy with best parameter is \", test_score)\nprint(\"Test recall with best parameters is \", test_recall)\nprint(\"Test AUC with the best parameter is \", test_auc)\n\nm = 'Decision Tree'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:11.239443Z","iopub.execute_input":"2022-09-07T10:06:11.239824Z","iopub.status.idle":"2022-09-07T10:06:11.311556Z","shell.execute_reply.started":"2022-09-07T10:06:11.239787Z","shell.execute_reply":"2022-09-07T10:06:11.310582Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(SelectedDTModel.feature_importances_)]).T","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:11.312909Z","iopub.execute_input":"2022-09-07T10:06:11.313333Z","iopub.status.idle":"2022-09-07T10:06:11.322204Z","shell.execute_reply.started":"2022-09-07T10:06:11.313297Z","shell.execute_reply":"2022-09-07T10:06:11.321035Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz \ndot_data=export_graphviz(SelectedDTModel, feature_names=X_trainval.columns.values.tolist(),out_file=None)\ngraph = graphviz.Source(dot_data)  \ngraph ","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:11.324770Z","iopub.execute_input":"2022-09-07T10:06:11.325533Z","iopub.status.idle":"2022-09-07T10:06:12.467178Z","shell.execute_reply.started":"2022-09-07T10:06:11.325490Z","shell.execute_reply":"2022-09-07T10:06:12.466063Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"best_score = 0\n\nfor M in range(2, 15, 2): # combines M trees\n    for d in range(1, 9): # maximum number of features considered at each split\n        for m in range(1, 9): # maximum depth of the tree\n            # train the model\n            # n_jobs(4) is the number of parallel computing\n            forestModel = RandomForestClassifier(n_estimators=M, max_features=d, n_jobs=4,\n                                          max_depth=m, random_state=0)\n        \n            # perform cross-validation\n            scores = cross_val_score(forestModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n\n            # compute mean cross-validation accuracy\n            score = np.mean(scores)\n\n            # if we got a better score, store the score and parameters\n            if score > best_score:\n                best_score = score\n                best_M = M\n                best_d = d\n                best_m = m\n\n# Rebuild a model on the combined training and validation set        \nSelectedRFModel = RandomForestClassifier(n_estimators=M, max_features=d,\n                                          max_depth=m, random_state=0).fit(X_trainval_scaled, Y_trainval )\n\nPredictedOutput = SelectedRFModel.predict(X_test_scaled)\ntest_score = SelectedRFModel.score(X_test_scaled, Y_test)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameters of M, d, m are: \", best_M, best_d, best_m)\nprint(\"Test accuracy with the best parameters is\", test_score)\nprint(\"Test recall with the best parameters is:\", test_recall)\nprint(\"Test AUC with the best parameters is:\", test_auc)\n\nm = 'Random Forest'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:06:12.469383Z","iopub.execute_input":"2022-09-07T10:06:12.469681Z","iopub.status.idle":"2022-09-07T10:06:39.339062Z","shell.execute_reply.started":"2022-09-07T10:06:12.469651Z","shell.execute_reply":"2022-09-07T10:06:39.336806Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"**AdaBoost**","metadata":{}},{"cell_type":"code","source":"best_score = 0\n\nfor M in range(2, 15, 2): # combines M trees\n    for lr in [0.0001, 0.001, 0.01, 0.1, 1]:\n        # train the model\n        boostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0)\n\n        # perform cross-validation\n        scores = cross_val_score(boostModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n\n        # compute mean cross-validation accuracy\n        score = np.mean(scores)\n\n        # if we got a better score, store the score and parameters\n        if score > best_score:\n            best_score = score\n            best_M = M\n            best_lr = lr\n\n# Rebuild a model on the combined training and validation set        \nSelectedBoostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0).fit(X_trainval_scaled, Y_trainval )\n\nPredictedOutput = SelectedBoostModel.predict(X_test_scaled)\ntest_score = SelectedRFModel.score(X_test_scaled, Y_test)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter of M is: \", best_M)\nprint(\"best parameter of LR is: \", best_lr)\nprint(\"Test accuracy with the best parameter is\", test_score)\nprint(\"Test recall with the best parameters is:\", test_recall)\nprint(\"Test AUC with the best parameters is:\", test_auc)\n\nm = 'AdaBoost'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:08:16.550354Z","iopub.execute_input":"2022-09-07T10:08:16.551401Z","iopub.status.idle":"2022-09-07T10:08:18.673957Z","shell.execute_reply.started":"2022-09-07T10:08:16.551361Z","shell.execute_reply":"2022-09-07T10:08:18.672592Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(SelectedBoostModel.feature_importances_)]).T","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:08:27.864746Z","iopub.execute_input":"2022-09-07T10:08:27.865385Z","iopub.status.idle":"2022-09-07T10:08:27.874537Z","shell.execute_reply.started":"2022-09-07T10:08:27.865346Z","shell.execute_reply":"2022-09-07T10:08:27.873405Z"},"trusted":true},"execution_count":57,"outputs":[]}]}